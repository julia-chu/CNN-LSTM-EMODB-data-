{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1D cnn for SER\n",
    "import tensorflow \n",
    "from tensorflow.keras.models import Model,Sequential\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.layers import Input,Conv1D,BatchNormalization,MaxPooling1D,LSTM,Dense,Activation,Layer\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import tensorflow.keras.backend as K\n",
    "import argparse\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "import platform\n",
    "import glob\n",
    "import ntpath\n",
    "import os\n",
    "from scipy.io import wavfile\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import speechpy\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "#from torch import Tensor\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "#import keras\n",
    "#from tensorflow.keras.np_utils import to_categorical\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import librosa\n",
    "\n",
    "\n",
    "datapath = '/Users/julia/Downloads/download/wav'\n",
    "classes = ['W','F','T','N'] # 7 classes\n",
    "\n",
    "\n",
    "seg_len = 16000  # sample rate 檔案中每秒鐘對這個聲音的取樣次數皆為16000\n",
    "seg_ov = int(seg_len*0.5) # 50% overlap 使這個變量step_size是的一半window_size\n",
    "\n",
    "def normalize(s): # 使用RMS normalization歸一化(Root Mean Square): 將峰值相加並除以峰值數量，使用新的平均峰值處理信號，具有不同波峰和波谷的長音頻文件上效果最好。\n",
    "    new_s = s/np.sqrt(np.sum(np.square((np.abs(s))))/len(s))\n",
    "    return new_s\n",
    "\n",
    "def countclasses(fnames):\n",
    "    dict = {classes[0]:0,classes[1]:0,classes[2]:0,classes[3]:0}\n",
    "    for name in fnames:\n",
    "        if name[5] in classes:  # 音檔名中第五個字母代表說話者的情感編號，若有對應classes相同的英文字母，則加入dict的類別數\n",
    "            dict[name[5]]+=1\n",
    "    return dict\n",
    "\n",
    "def data1d(path): # 數據處理\n",
    "\n",
    "    fnames = os.listdir(datapath)\n",
    "    dict = countclasses(fnames) # 將所有音檔編號對應數量存為dict\n",
    "    print('Total Data',dict)\n",
    " \n",
    "    num_cl = len(classes) # 7 classes\n",
    "  # 建立 train,test,val的dictionary\n",
    "    train_dict = {classes[0]:0,classes[1]:0,classes[2]:0,classes[3]:0}\n",
    "    test_dict = {classes[0]:0,classes[1]:0,classes[2]:0,classes[3]:0}\n",
    "    val_dict = {classes[0]:0,classes[1]:0,classes[2]:0,classes[3]:0}\n",
    "\n",
    "    for i in range(num_cl):\n",
    "        cname =  list(dict.keys())[i]\n",
    "        cnum = dict[cname]\n",
    "        t = round(0.8*cnum) # 將 t 設為各情緒類別數據集的80%\n",
    "        test_dict[cname] = int(cnum - t) # test data為各情緒類別數據集的 20 %\n",
    "        val_dict[cname] = int(round(0.2*t)) #  從ｔ提取20%作為 validation data\n",
    "        train_dict[cname] = int(t - val_dict[cname]) # 剩下的80%的t 作為train data\n",
    "        print('Class:',cname,'train:',train_dict[cname],'val:',val_dict[cname],'test:',test_dict[cname])\n",
    "\n",
    "    x_train = []\n",
    "    y_train = []\n",
    "    x_test = []\n",
    "    y_test = []\n",
    "    x_val = []\n",
    "    y_val = []\n",
    "\n",
    "    count = {classes[0]:0,classes[1]:0,classes[2]:0,classes[3]:0}\n",
    "\n",
    "    for name in fnames:\n",
    "        # 若音檔名中第五個字母有對應classes相同的英文字母\n",
    "        if name[5] in classes:\n",
    "            sig,fs = librosa.load(datapath+'/'+name, sr=16000)  # 將音頻數據加載為浮點時間序列, sr為音檔的sample rate =16000 --> sig為讀取的數據、fs為sample rate \n",
    "            # normalize signal\n",
    "            data = normalize(sig) # 將讀取的數據(sig)歸一化\n",
    "            \n",
    "            ## 若讀取的音檔數據長度 小於seg_len(sample rate)\n",
    "            if(len(data) < seg_len):  \n",
    "                pad_len = int(seg_len - len(data))  \n",
    "                pad_rem = int(pad_len % 2) #\n",
    "                pad_len /= 2\n",
    "                signal = np.pad(data,(int(pad_len), int(pad_len+pad_rem)),'constant',constant_values=0)\n",
    "            ## 若讀取的音檔數據長度 大於seg_len(sample rate)\n",
    "            elif(len(data) > seg_len):\n",
    "                signal = []\n",
    "                end = seg_len\n",
    "                st = 0\n",
    "                while(end < len(data)):  # 數據長度大於seg len時\n",
    "                    signal.append(data[st:end]) \n",
    "                    st = st + seg_ov   # seg_ov = 8000\n",
    "                    end = st + seg_len\n",
    "                signal = np.array(signal)\n",
    "                if(end >= len(data)):  # 直到數據長度小於seg len時\n",
    "                    num_zeros = int(end-len(data)) \n",
    "                    if(num_zeros > 0):\n",
    "                        n1 = np.array(data[st:end])\n",
    "                        n2 = np.zeros([num_zeros])  # 返回一個用0填充的數組\n",
    "                        s = np.concatenate([n1,n2],0)  # 垂直堆疊矩陣\n",
    "                    else:\n",
    "                        s = np.array(data[int(st):int(end)])\n",
    "                signal = np.vstack([signal,s]) # 垂直堆疊矩陣\n",
    "                \n",
    "            ## 若讀取的音檔數據長度 等於seg_len(sample rate)\n",
    "            else:\n",
    "                signal = data\n",
    "            \n",
    "            \n",
    "            ''''處理train,val,test數據資料'''\n",
    "            if(count[name[5]] < train_dict[name[5]]):\n",
    "                if(signal.ndim>1): #若signal維度大於1\n",
    "                    for i in range(signal.shape[0]):\n",
    "                        x_train.append(signal[i])\n",
    "                        y_train.append(name[5])\n",
    "                else:\n",
    "                    x_train.append(signal)\n",
    "                    y_train.append(name[5])\n",
    "            else:\n",
    "                if((count[name[5]]-train_dict[name[5]]) < val_dict[name[5]]):\n",
    "                    if(signal.ndim>1):\n",
    "                        for i in range(signal.shape[0]):\n",
    "                            x_val.append(signal[i])\n",
    "                            y_val.append(name[5])\n",
    "                    else:\n",
    "                        x_val.append(signal)\n",
    "                        y_val.append(name[5])\n",
    "                else:\n",
    "                    if(signal.ndim>1):\n",
    "                        for i in range(signal.shape[0]):\n",
    "                            x_test.append(signal[i])\n",
    "                            y_test.append(name[5])\n",
    "                    else:\n",
    "                        x_test.append(signal)\n",
    "                        y_test.append(name[5])\n",
    "            count[name[5]]+=1\n",
    "    return np.float32(x_train),y_train,np.float32(x_test),y_test,np.float32(x_val),y_val\n",
    "\n",
    "def string2num(y): # 將資料集中對應的情感字母編號轉成數字1-6\n",
    "    y1 = []\n",
    "    for i in y:\n",
    "        if(i == classes[0]):\n",
    "            y1.append(0)\n",
    "        elif(i == classes[1]):\n",
    "            y1.append(1)\n",
    "        elif(i == classes[2]):\n",
    "            y1.append(2)\n",
    "        else:\n",
    "            y1.append(3)\n",
    "    y1 = np.float32(np.array(y1)) # list to array\n",
    "    return y1\n",
    "\n",
    "def load_data():\n",
    "    x_tr,y_tr,x_t,y_t,x_v,y_v = data1d(datapath)\n",
    "    y_tr = string2num(y_tr)\n",
    "    y_t = string2num(y_t)\n",
    "    y_v = string2num(y_v)\n",
    "    return x_tr, y_tr, x_t, y_t, x_v, y_v\n",
    "           \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/julia/Downloads/download/wav'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-69923b586ba6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;31m# load data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m     \u001b[0mx_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloadData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_fc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-69923b586ba6>\u001b[0m in \u001b[0;36mloadData\u001b[0;34m()\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mloadData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m     \u001b[0mx_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m     \u001b[0mx_tr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_tr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_tr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0mx_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-2b80a6cdb1c9>\u001b[0m in \u001b[0;36mload_data\u001b[0;34m()\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m     \u001b[0mx_tr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_tr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx_t\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_t\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx_v\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_v\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatapath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m     \u001b[0my_tr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstring2num\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_tr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[0my_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstring2num\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-2b80a6cdb1c9>\u001b[0m in \u001b[0;36mdata1d\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdata1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# 數據處理\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0mfnames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatapath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m     \u001b[0mdict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcountclasses\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfnames\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# 將所有音檔編號對應數量存為dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Total Data'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/julia/Downloads/download/wav'"
     ]
    }
   ],
   "source": [
    "'''模型訓練:一維 CNN-LSTM'''\n",
    "def emo1d(input_shape, num_classes, args):\n",
    "    model = Sequential(name='Emo1D')\n",
    "\n",
    "    # 第一層CNN (一維度卷基層)\n",
    "    model.add(Conv1D(filters=64, kernel_size=(3), strides=1, padding='same', data_format='channels_last',\n",
    "                     input_shape=input_shape))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('elu'))\n",
    "    model.add(MaxPooling1D(pool_size=4, strides=4))\n",
    "\n",
    "    # 第二層CNN\n",
    "    model.add(Conv1D(filters=64, kernel_size=3, strides=1, padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('elu'))\n",
    "    model.add(MaxPooling1D(pool_size=4, strides=4))\n",
    "\n",
    "    # 第三層CNN\n",
    "    model.add(Conv1D(filters=128, kernel_size=3, strides=1, padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('elu'))\n",
    "    model.add(MaxPooling1D(pool_size=4, strides=4))\n",
    "\n",
    "    # 第四層CNN\n",
    "    model.add(Conv1D(filters=128, kernel_size=3, strides=1, padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('elu'))\n",
    "    model.add(MaxPooling1D(pool_size=4, strides=4))\n",
    "\n",
    "    # LSTM\n",
    "    model.add(LSTM(units=args.num_fc,return_sequences=True))\n",
    "    model.add(Activation('tanh'))\n",
    "    model.add(LSTM(units=args.num_fc,return_sequences=False))\n",
    "\n",
    "    # FC layer\n",
    "    model.add(Dense(units=num_classes, activation='softmax'))\n",
    "\n",
    "    # Model compilation\n",
    "    opt = optimizers.SGD(lr=args.learning_rate, decay=args.decay, momentum=args.momentum, nesterov=True)\n",
    "    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def train(model, x_tr, y_tr, x_val, y_val, args):\n",
    "    es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=8) # 當被監測的數量不再提升，則停止訓練\n",
    "    mc = ModelCheckpoint('best_model.h5', monitor='val_categorical_accuracy', mode='max', verbose=1,\n",
    "                         save_best_only=True) # 在每個訓練期之後保存模型\n",
    "    history = model.fit(x_tr, y_tr, epochs=args.num_epochs, batch_size=args.batch_size, validation_data=(x_val, y_val),\n",
    "                        callbacks=[es, mc])\n",
    "    return model\n",
    "\n",
    "\n",
    "def test(model, x_t, y_t):\n",
    "    saved_model = load_model('best_model.h5',custom_objects={'SeqSelfAttention':SeqSelfAttention})\n",
    "    score = saved_model.evaluate(x_t, y_t, batch_size=20)\n",
    "    print(score)\n",
    "    return score\n",
    "\n",
    "\n",
    "def loadData():\n",
    "    x_tr, y_tr, x_t, y_t, x_val, y_val = load_data()\n",
    "    x_tr = x_tr.reshape(-1, x_tr.shape[1], 1)\n",
    "    x_t = x_t.reshape(-1, x_t.shape[1], 1)\n",
    "    x_val = x_val.reshape(-1, x_val.shape[1], 1)\n",
    "    y_tr = to_categorical(y_tr)\n",
    "    y_t = to_categorical(y_t)\n",
    "    y_val = to_categorical(y_val)\n",
    "    return x_tr, y_tr, x_t, y_t, x_val, y_val\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    parser = argparse.ArgumentParser()\n",
    "    args = parser.parse_args(args=[])\n",
    "\n",
    "    # load data\n",
    "    x_tr, y_tr, x_t, y_t, x_val, y_val = loadData()\n",
    "\n",
    "    args.num_fc = 64\n",
    "    args.batch_size = 32\n",
    "    args.num_epochs = 200 # best model will be saved before number of epochs reach this value\n",
    "    args.learning_rate = 0.0001\n",
    "    args.decay = 1e-6\n",
    "    args.momentum = 0.9\n",
    "    \n",
    "\n",
    "    # define model\n",
    "    model = emo1d(input_shape=x_tr.shape[1:], num_classes=len(np.unique(np.argmax(y_tr, 1))), args=args)\n",
    "    model.summary()\n",
    "\n",
    "    # train model\n",
    "    model = train(model, x_tr, y_tr, x_val, y_val, args=args)\n",
    "\n",
    "    # test model\n",
    "    score = test(model, x_t, y_t) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 2s 111ms/step - loss: 0.4767 - categorical_accuracy: 0.8300\n",
      "[0.4766516387462616, 0.829971194267273]\n"
     ]
    }
   ],
   "source": [
    "score = test(model, x_t, y_t) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
